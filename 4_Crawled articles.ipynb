{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from article_lib import *\n",
    "from mitie_lib import *\n",
    "import pandas as pd\n",
    "\n",
    "article_folders = ['crawled', 'fakenewschallenge', 'KaggleData']\n",
    "working_folder = \"..\\\\Articles\"\n",
    "fakes_dataset = pd.read_csv(\"..\\\\Data\\\\fakes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "def process_folder_of_articles(in_folder, out_file, fakes, batch_size=1000, start=0):\n",
    "    print \"Starting processing folder %s...\"%folder\n",
    "    articles = glob.glob(folder + \"\\\\*.xml\")\n",
    "    length = len(articles)\n",
    "    print \"Found articles: %i.\"%length\n",
    "    all_fakes = 0\n",
    "    for batch_start in range(start, length, batch_size):\n",
    "        batch_num = batch_start/batch_size + 1\n",
    "        print \"Processing batch #%i...\"%batch_num\n",
    "        \n",
    "        start = time.time()\n",
    "        batch = [articles[i] for i in range(batch_start, batch_start+batch_size)]\n",
    "        fakes_found = process_batch(batch, out_file, fakes)\n",
    "        all_fakes += fakes_found\n",
    "        print \"Found %i fakes. Results saved in file: %s. \"%(fakes_found, out_file)\n",
    "        end = time.time()\n",
    "        \n",
    "        batch_time = end-start\n",
    "        batches_more = (length - batch_start - batch_size)/batch_size\n",
    "        left_time = batch_time * batches_more\n",
    "        \n",
    "        print \"Batch #%i finished. Time take: %s. To finish: %s\"%(batch_num,str(batch_time),str(left_time))\n",
    "    \n",
    "    print \"Folder %s done. %i fakes found.\"%(folder,all_fakes)\n",
    "\n",
    "def process_batch(batch, out_file, fakes):\n",
    "    df = read_list_of_articles_as_dataset(batch)\n",
    "    fake_columns = []\n",
    "    \n",
    "    # try to extract relations for each fake\n",
    "    for fake in fakes.iterrows():\n",
    "        column_name = \"fake_%i\"%fake[\"Id\"]\n",
    "        df[column_name + \"_title\"] = df.apply(lambda row: assign_fake_score(row[\"Title\"], fake[\"Subject\"], fake[\"Object\"], fake[\"Predicate\"]), axis=1)\n",
    "        df[column_name + \"_body\"] = df.apply(lambda row: assign_fake_score(row[\"Body\"], fake[\"Subject\"], fake[\"Object\"], fake[\"Predicate\"]), axis=1)\n",
    "        fake_columns.append(column_name + \"_title\")\n",
    "        fake_columns.append(column_name + \"_body\")\n",
    "        \n",
    "    # split results on two columns\n",
    "    fake_columns_scores = []\n",
    "    for fake_column in fake_columns:\n",
    "        df[fake_column + \"_score\"] = df.apply(lambda row: row[fake_column][0])\n",
    "        fake_columns_scores.append(fake_column+ \"_score\")\n",
    "        df[fake_column + \"_text\"] = df.apply(lambda row: row[fake_column][1])\n",
    "        del df[fake_column]\n",
    "        \n",
    "    # calculate results\n",
    "    fakes_found = df[fake_columns_scores].apply(lambda row: 1 if row.any(lambda r: r != 0) else 0, axis=1).sum()\n",
    "    \n",
    "    # remove extra data\n",
    "    del df[\"BinaryRelationId\"]\n",
    "    del df[\"Title\"]\n",
    "    del df[\"Body\"]\n",
    "    \n",
    "    # append to existsing file or create new\n",
    "    if os.path.exists(out_file):\n",
    "        with open(out_file, 'a') as f:\n",
    "            df.to_csv(f, header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(out_file, index=False)\n",
    "    return fakes_found\n",
    "\n",
    "## select the best result\n",
    "def assign_fake_score(text, subject_text, object_text, predicate):\n",
    "    relations = [r for r in relations \n",
    "                   for relations in [find_binary_relation_in_text(text.upper(), subject_text, object_text, predicate),\n",
    "                                     find_binary_relation_in_text(text.lower(), subject_text, object_text, predicate),\n",
    "                                     find_binary_relation_in_text(text, subject_text, object_text, predicate)]]\n",
    "    \n",
    "    if(len(relations) == 0):\n",
    "        return (0, \"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
